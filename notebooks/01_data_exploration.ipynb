{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c2f9db7",
   "metadata": {},
   "source": [
    "# Data Exploration Notebook\n",
    "\n",
    "This notebook provides a comprehensive framework for exploring your dataset. Follow the sections below to get a thorough understanding of your data.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Data Loading](#data-loading)\n",
    "2. [Basic Information](#basic-information)\n",
    "3. [Missing Values Analysis](#missing-values-analysis)\n",
    "4. [Data Types & Distributions](#data-types--distributions)\n",
    "5. [Statistical Summary](#statistical-summary)\n",
    "6. [Initial Visualizations](#initial-visualizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3632d0cf",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3ed89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# EDA toolkit imports\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../plots')\n",
    "\n",
    "from data_loader import DataLoader\n",
    "from statistical_analysis import StatisticalAnalyzer\n",
    "from histogram import create_histogram, create_multiple_histograms\n",
    "from box_plot import create_box_plot\n",
    "from correlation_matrix import create_correlation_heatmap\n",
    "from utils import PlotConfig\n",
    "\n",
    "# Configure plotting\n",
    "plot_config = PlotConfig()\n",
    "plot_config.set_style()\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae123d4c",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load your dataset using the EDA toolkit's DataLoader class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = DataLoader()\n",
    "\n",
    "# Load your data (replace with your file path)\n",
    "# For CSV files:\n",
    "# data = loader.load_csv('../data/raw/your_data.csv')\n",
    "\n",
    "# For Excel files:\n",
    "# data = loader.load_excel('../data/raw/your_data.xlsx')\n",
    "\n",
    "# For demonstration, let's create sample data\n",
    "np.random.seed(42)\n",
    "sample_data = {\n",
    "    'age': np.random.randint(18, 80, 1000),\n",
    "    'income': np.random.normal(50000, 15000, 1000),\n",
    "    'education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], 1000),\n",
    "    'experience': np.random.randint(0, 40, 1000),\n",
    "    'salary': np.random.normal(60000, 20000, 1000),\n",
    "    'category': np.random.choice(['A', 'B', 'C'], 1000)\n",
    "}\n",
    "\n",
    "# Add some missing values\n",
    "sample_data['income'][np.random.choice(1000, 50, replace=False)] = np.nan\n",
    "sample_data['salary'][np.random.choice(1000, 30, replace=False)] = np.nan\n",
    "\n",
    "data = pd.DataFrame(sample_data)\n",
    "\n",
    "print(f\"Data loaded successfully!\")\n",
    "print(f\"Shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa35cd2",
   "metadata": {},
   "source": [
    "## Basic Information\n",
    "\n",
    "Get an overview of the dataset structure and basic properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620d4c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset shape\n",
    "print(f\"Dataset Shape: {data.shape}\")\n",
    "print(f\"Number of rows: {data.shape[0]}\")\n",
    "print(f\"Number of columns: {data.shape[1]}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Column information\n",
    "print(\"Column Information:\")\n",
    "print(data.info())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# First few rows\n",
    "print(\"First 5 rows:\")\n",
    "display(data.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Data types\n",
    "print(\"Data Types:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Memory usage\n",
    "print(\"Memory Usage:\")\n",
    "print(f\"Total memory usage: {data.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51dfd52",
   "metadata": {},
   "source": [
    "## Missing Values Analysis\n",
    "\n",
    "Analyze missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values summary\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing_Count': data.isnull().sum(),\n",
    "    'Missing_Percentage': (data.isnull().sum() / len(data) * 100).round(2)\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(\"Missing Values Summary:\")\n",
    "display(missing_summary[missing_summary['Missing_Count'] > 0])\n",
    "\n",
    "# Visualize missing values\n",
    "if missing_summary['Missing_Count'].sum() > 0:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Missing values heatmap\n",
    "    sns.heatmap(data.isnull(), ax=ax1, cbar=True, cmap='viridis')\n",
    "    ax1.set_title('Missing Values Heatmap')\n",
    "    \n",
    "    # Missing values bar plot\n",
    "    missing_cols = missing_summary[missing_summary['Missing_Count'] > 0]\n",
    "    if not missing_cols.empty:\n",
    "        missing_cols['Missing_Percentage'].plot(kind='bar', ax=ax2)\n",
    "        ax2.set_title('Missing Values Percentage by Column')\n",
    "        ax2.set_ylabel('Percentage (%)')\n",
    "        plt.setp(ax2.get_xticklabels(), rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No missing values found in the dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4825804",
   "metadata": {},
   "source": [
    "## Data Types & Distributions\n",
    "\n",
    "Analyze data types and explore distributions of different variable types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate columns by type\n",
    "numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_columns = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "datetime_columns = data.select_dtypes(include=['datetime64']).columns.tolist()\n",
    "\n",
    "print(f\"Numeric columns ({len(numeric_columns)}): {numeric_columns}\")\n",
    "print(f\"Categorical columns ({len(categorical_columns)}): {categorical_columns}\")\n",
    "print(f\"Datetime columns ({len(datetime_columns)}): {datetime_columns}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Unique values in categorical columns\n",
    "if categorical_columns:\n",
    "    print(\"Unique values in categorical columns:\")\n",
    "    for col in categorical_columns:\n",
    "        unique_count = data[col].nunique()\n",
    "        print(f\"{col}: {unique_count} unique values\")\n",
    "        if unique_count <= 10:\n",
    "            print(f\"  Values: {data[col].unique()}\")\n",
    "        print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Cardinality analysis\n",
    "cardinality_df = pd.DataFrame({\n",
    "    'Column': data.columns,\n",
    "    'Unique_Count': [data[col].nunique() for col in data.columns],\n",
    "    'Unique_Percentage': [data[col].nunique() / len(data) * 100 for col in data.columns]\n",
    "}).round(2)\n",
    "\n",
    "print(\"Cardinality Analysis:\")\n",
    "display(cardinality_df.sort_values('Unique_Percentage', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9868e21c",
   "metadata": {},
   "source": [
    "## Statistical Summary\n",
    "\n",
    "Generate comprehensive statistical summaries using the EDA toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461d6bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize statistical analyzer\n",
    "analyzer = StatisticalAnalyzer(data)\n",
    "\n",
    "# Generate comprehensive statistics\n",
    "stats_summary = analyzer.describe_all()\n",
    "\n",
    "# Display numeric summary\n",
    "if 'numeric_summary' in stats_summary:\n",
    "    print(\"Numeric Variables Summary:\")\n",
    "    display(stats_summary['numeric_summary'])\n",
    "    \n",
    "    print(\"\\nExtended Numeric Statistics:\")\n",
    "    display(stats_summary['numeric_extended'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Display categorical summary\n",
    "if 'categorical_summary' in stats_summary:\n",
    "    print(\"Categorical Variables Summary:\")\n",
    "    display(stats_summary['categorical_summary'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Distribution analysis\n",
    "if numeric_columns:\n",
    "    print(\"Distribution Analysis:\")\n",
    "    dist_analysis = analyzer.distribution_analysis(numeric_columns)\n",
    "    \n",
    "    dist_df = pd.DataFrame(dist_analysis).T\n",
    "    display(dist_df[['mean', 'median', 'std', 'skewness', 'kurtosis', 'shape']].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87690a4",
   "metadata": {},
   "source": [
    "## Initial Visualizations\n",
    "\n",
    "Create initial visualizations to understand data distributions and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c64848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms for numeric variables\n",
    "if len(numeric_columns) > 0:\n",
    "    print(\"Distribution of Numeric Variables:\")\n",
    "    \n",
    "    if len(numeric_columns) <= 4:\n",
    "        # Create individual histograms\n",
    "        for col in numeric_columns:\n",
    "            create_histogram(data, col, save_path=f'../figures/exploratory/{col}_histogram.png')\n",
    "            plt.show()\n",
    "    else:\n",
    "        # Create multiple histograms in grid\n",
    "        create_multiple_histograms(data, numeric_columns, \n",
    "                                 save_path='../figures/exploratory/numeric_distributions.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec089ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for numeric variables\n",
    "if len(numeric_columns) > 1:\n",
    "    print(\"Box Plots of Numeric Variables:\")\n",
    "    create_box_plot(data, numeric_columns, \n",
    "                   save_path='../figures/exploratory/numeric_boxplots.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9620209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "if len(numeric_columns) > 1:\n",
    "    print(\"Correlation Analysis:\")\n",
    "    \n",
    "    # Correlation matrix\n",
    "    create_correlation_heatmap(data, numeric_columns,\n",
    "                              save_path='../figures/exploratory/correlation_matrix.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistical correlation analysis\n",
    "    corr_analysis = analyzer.correlation_analysis()\n",
    "    \n",
    "    if 'high_correlations' in corr_analysis and not corr_analysis['high_correlations'].empty:\n",
    "        print(\"\\nHigh Correlations (|r| > 0.7):\")\n",
    "        display(corr_analysis['high_correlations'].round(3))\n",
    "    else:\n",
    "        print(\"\\nNo high correlations found (|r| > 0.7)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b338597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variable analysis\n",
    "if categorical_columns:\n",
    "    print(\"Categorical Variables Analysis:\")\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        print(f\"\\n{col} - Value Counts:\")\n",
    "        value_counts = data[col].value_counts()\n",
    "        print(value_counts)\n",
    "        \n",
    "        # Create count plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.countplot(data=data, x=col)\n",
    "        plt.title(f'Count Plot: {col}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33cfd0a",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "Based on the initial exploration, document key findings and plan next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b7ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of key findings\n",
    "print(\"=\" * 60)\n",
    "print(\"KEY FINDINGS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n1. Dataset Overview:\")\n",
    "print(f\"   - Shape: {data.shape}\")\n",
    "print(f\"   - Numeric columns: {len(numeric_columns)}\")\n",
    "print(f\"   - Categorical columns: {len(categorical_columns)}\")\n",
    "print(f\"   - Missing values: {data.isnull().sum().sum()} total\")\n",
    "\n",
    "if numeric_columns:\n",
    "    print(f\"\\n2. Numeric Variables:\")\n",
    "    for col in numeric_columns:\n",
    "        skewness = data[col].skew()\n",
    "        missing_pct = data[col].isnull().sum() / len(data) * 100\n",
    "        print(f\"   - {col}: Mean={data[col].mean():.2f}, Skew={skewness:.2f}, Missing={missing_pct:.1f}%\")\n",
    "\n",
    "if categorical_columns:\n",
    "    print(f\"\\n3. Categorical Variables:\")\n",
    "    for col in categorical_columns:\n",
    "        unique_count = data[col].nunique()\n",
    "        most_common = data[col].mode()[0] if not data[col].mode().empty else 'N/A'\n",
    "        print(f\"   - {col}: {unique_count} unique values, Most common: {most_common}\")\n",
    "\n",
    "print(f\"\\n4. Next Steps:\")\n",
    "print(f\"   - Proceed to data cleaning notebook if issues found\")\n",
    "print(f\"   - Continue with feature analysis notebook\")\n",
    "print(f\"   - Explore relationships between variables\")\n",
    "print(f\"   - Consider domain-specific analysis\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
